

# RL


## models /references

|  模型     |  paper | year + 会议 |   简介|  创新点 | 缺陷| code |
| :-------- | -----:| ----:|------:|--------:|:--: |
||Playing Atari with Deep Reinforcement Learning|2013|
|| Nature Human Level Control through Deep Reinforcement Learning|Nature 2015| |
|[alphago]()||2016|
|[alphazero]()|
|[ICM](https://pathak22.github.io/noreward-rl/)|Curiosity-driven Exploration by Self-supervised Prediction|ICML 2017|利用Curiosity解决sparse reward的问题 |


## code
- [Catch 游戏：用TensorFlow构建你的第一个游戏AI](https://www.jiqizhixin.com/articles/2017-11-16-7)  太简单了
- [pong from pixels 超赞的博客](http://karpathy.github.io/2016/05/31/rl/)

[象棋]

- [code & course](https://github.com/dennybritz/reinforcement-learning)
- [pytorch RL](http://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html)
- [200行Keras代码实现DQN玩转FlappyBird](https://ricky.moe/2016/07/19/Keras-DQN-Flappybird/)


[德州扑克 : NIPS 2017最佳论文出炉：CMU冷扑大师不完美信息博弈研究获奖](https://www.jiqizhixin.com/articles/2017-11-16-4)


[blog](https://zhuanlan.zhihu.com/p/25473646)

## dataset

貌似不需要dataset，直接上。


## 疑问

为什么叫增强/强化学习？跟online learning什么区别？
