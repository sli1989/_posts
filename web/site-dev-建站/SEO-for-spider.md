---
title: 关于SEO
date: 2018-01-25 03:08:53
tags: ["domain","SEO"]
categories:
- web
- site-dev
---

# 简介

## 如何检查自己网站是否被baidu google检索
site:xu-song.top git
site:xu-song.github.io git

## 提交百度检索

https://ziyuan.baidu.com/linksubmit/url

 >百度搜索资源平台为站长提供链接提交通道，您可以提交想被百度收录的链接，百度搜索引擎会按照标准处理，但不保证一定能够收录您提交的链接。

[Hexo 博客添加百度sitemap](https://blog.paddings.cn/2016/05/14/blog/hexo-sitemap/)

[hexo部署在github，用百度的站长收录sitemap，抓取失败怎么办？](https://www.zhihu.com/question/37633687)
Github屏蔽了百度爬虫。
除了sitemap还有其他提交方法，还可以采用主动推送和自动推送，


## 为什么我的博客始终无法被百度收录

我在GoDaddy购买了域名，完成了在谷歌搜录，百度完成自动推送的设置后在sitemap一栏中填入我的域名始终显示sitemap抓取失败，请问这是什么问题我该如何解决呢   -- 知乎

github 禁止了百度的爬虫，你可以在 国内的 coding.net 上放一份，然后修改域名服务商的 CNAME 让国内的指向 coding.net ，国外的依然指向 github。具体你自己查下吧

> 就算放开了，肯定也没有国内的vps收录快。还有就是并不是所有的ip地址的权重都一样。爬虫有自己喜欢和不喜欢的ip群

如果完全没有外链，也不向百度提交，相当于孤岛，是不可能被收录的。
除非有人替你提交，或者本身百度数据库有你域名的记录。

没外链不代表孤岛，没外链你DNS修改时候百度等也有可能会知道，参考dnspod和百度合作的某文章……

## 有多个域名，怎么做最符合 SEO?

把其他域名都转发到主域名。很多人把不同的域名都解析到同一个网站，这样导致的结果是其他的域名没有对主域名起到任何作用，反而可能导致负面影响，如：让搜索引擎分不清到底哪一个是主域名。

搜索引擎对同一ip下的域名有互相推广的作用，给的比重越来越小了，多个域名同时解析到一个主机上，对SEO是有影响的，比如说：排名不好、PR值低、收录量少等问题。

对于多域名绑定建议从下面入手：

    1.使用301重定向功能。关于301重定向的操作需要注意的是：不要将次要网站中的所有网页的流量都重定向到主站上，这样做虽然节省了很多工作量，但是如果用户从搜索引擎上找过来，访问到的网页并不是他想要的内容，就会损失流量。尽可能做到页对页的重定向，保证用户从搜索引擎找过来的网页即使不是绝对匹配也是相关的内容。

    2.给次要的网站首页做一个导航,把流量指引到主站上；

    3.给次要的域名做URL转发；

一定要这样做：实现301重定向把次域名重定向到主域名去，避免权重分散，甚至被K，或者影响SEO排名。

- 301 redirect:：301代表永久性转移。301重定向是网页更改地址后对搜索引擎最友好的方法，只要不是暂时搬移的情况，都建议使用301来做转址。
- 302 redirect:：302代表暂时性转移。在前些年，不少Black Hat SEO曾广泛应用这项技术作弊。各大主要搜索引擎均加强了打击力度。(怎么作弊？)

当网页A用301重定向转到网页B时，搜索引擎可以肯定网页A永久的改变位置，或者说实际上不存在了，搜索引擎就会把网页B当作唯一有效目标。好处是，第一，没有网址规范化问题，第二，也很重要的，网页A的PR网页级别会传到网页B。


## robots.txt

robots.txt位置固定，sitemap.xml需要在robots.txt中指定路径

## sitemap
爬虫会通过网页内部的链接发现新的网页。但是如果没有连接指向的网页怎么办?或者用户输入条件生成的动态网页怎么办?能否让网站管理员通知搜索引擎他们网站上有哪些可供抓取的网页?这就是sitemap，最简单的 Sitepmap 形式就是XML文件，在其中列出网站中的网址以及关于每个网址的其他数据(上次更新的时间、更改的频率以及相对于网站上其他网址的重要程度等等)，利用这些信息搜索引擎可以更加智能地抓取网站内容。

新的问题来了，爬虫怎么知道这个网站有没有提供sitemap文件，或者说网站管理员生成了sitemap，(可能是多个文件)，爬虫怎么知道放在哪里呢?

由于robots.txt的位置是固定的，于是大家就想到了把sitemap的位置信息放在robots.txt里。这就成为robots.txt里的新成员了。


站点地图对于百度失效。可以用主动推送和自动推送，



# 怎样判断网站有网址规范化问题？
1) 查一下这些URL是否都有差不多的PR值和网页快照：

http://domainname.com
http://www.domainname.com/index.html
http://domainname.com/index.html
http://www.domainname.com

2)搜一下site:domain.com看是否结果中有多个主页版本。

3)你的网站是否在Google有大量网页被标为“ 补充材料”(Supplemental Result)。一般认为被归为“ 补充材料”是网址规范化问题的征兆。

reference： https://www.seozac.com/seo/301-redirect/

site:.top
# tips
1. edu和gov后缀的域名天生权重更高。有些域名天生反链高，比如xxx   sex   之类的等等！
    - 百度说：使用何种形式的域名后缀对百度网页搜索没有影响

2. 注册时间越早的域名，越有利于排名。

3. 到期时间越晚的域名，越有利于排名。

4. 不同的子域名是会被当作独立网站处理的，不能继承主域名的权重。

5. 不同国家的域名，在本国会越有利于排名，比如http://abc.cn在中国会排名更好，而http://abc.us在美国会排名更好。

一个网站有多个域名没问题，请做好301跳转，别每个域名都可以访问。

gov和edu对排名有利，但对大多数人没什么指导意义，因为你根本弄不到这种后缀的域名。

域名买卖历史，（不涉及到违规行业越好）


惩罚 & 奖励
- 关键词堆砌
- 频繁的修改网页title、description和keywords
- 网站加上黑链
- 短时间内频繁的增加外链，或者短时间内大量的删除外链
- 服务器不稳定，网站经常打不开活域名解析错误。
- 全站 HTTPS，谷歌对 HTTPS 有加分
- 响应式设计，谷歌对提供友好移动端友好页面有加分
- AMP，谷歌对提供 AMP 支持的网站有加分
- PWA，谷歌对 PWA 有加分
- 加载优化，谷歌对 Pageseed 测试 90 分以上的网站有加分

## tricks

有很多大学生在他们大学的个人网站上出卖链接。搜索引擎怎样去辨别哪些来自.edu的链接是自然的？哪些又是买卖的呢？


## reference
https://www.webmasterworld.com/forum25/3716.htm
http://www.ehcoo.com/seo.html
[百度站长平台关于SEO的建议](https://ziyuan.baidu.com/college/articleinfo?id=36)
[自动推送Hexo博客文章至百度](https://lemonxq.cn/2017/11/23/[%E8%87%AA%E5%88%B6%E5%B7%A5%E5%85%B7]%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E6%8E%A8%E9%80%81Hexo%E5%8D%9A%E5%AE%A2%E6%96%87%E7%AB%A0%E8%87%B3%E7%99%BE%E5%BA%A6/) 待看

## 待续
